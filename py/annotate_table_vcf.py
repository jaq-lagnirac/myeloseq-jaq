# Justin Caringal
# Reads in directory of VCF files and annotates inputted table with
# set/source of coverage

import os
import sys
import argparse
import logging
import pandas as pd

VCF_SUFFIX = '.annotated_filtered.vcf'

SEP = '\t'
FILE_SEP = '.'
SET_BEGIN = 'set='
SET_END = ';'

EXIT = 'Exiting program.'
ROUNDING_DECIMALS = 3

# global vars
file_accesses = 0
total_annotations = 0
dragen_counter = 0
pindel_counter = 0
dragen_pindel_counter = 0
unknown_counter = 0
empty_counter = 0
not_found = 0
off_by_one = 0

# global lists
obo_list = []
nf_list = []
files_used_list = []


SCRIPT_PATH = os.path.abspath(__file__)
FORMAT = '[%(asctime)s] %(levelname)s %(message)s'
l = logging.getLogger()
lh = logging.StreamHandler()
lh.setFormatter(logging.Formatter(FORMAT))
l.addHandler(lh)
l.setLevel(logging.INFO)
debug = l.debug; info = l.info; warning = l.warning; error = l.error

DESCRIPTION = '''

Takes comparison table generated by coverage_table.py and a directory of VCF files to

annotated the table with the source (i.e. the "set") of the coverage

'''

EPILOG = '''

Outputs statistics in .err file.

'''

class CustomFormatter(argparse.ArgumentDefaultsHelpFormatter,
    argparse.RawDescriptionHelpFormatter):
  pass
parser = argparse.ArgumentParser(description=DESCRIPTION, epilog=EPILOG,
  formatter_class=CustomFormatter)

parser.add_argument('coverage_table',
                    help='TSV table to be annotated')
parser.add_argument('directory',
                    help='Directory of VCF files')
parser.add_argument('-v', '--verbose',
                    action='store_true',
                    help='Set logging level to DEBUG')

args = parser.parse_args()

if args.verbose:
  l.setLevel(logging.DEBUG)



def count_files(dir_path):
  total_file_count = 0
  vcf_suffix_count = 0

  # iterate through directory
  for path in os.listdir(dir_path):
    
    #create new file path
    full_path = os.path.join(dir_path, path)

    # if current path is a file
    if os.path.isfile(full_path):
      total_file_count += 1

      # checks for proper extension
      ext_location = path.index(FILE_SEP)
      if path[ext_location : ] == VCF_SUFFIX:
        vcf_suffix_count += 1
  
  return total_file_count, vcf_suffix_count



def add_set(row):

  # connecting global vars
  global file_accesses
  global total_annotations
  global dragen_counter
  global pindel_counter
  global dragen_pindel_counter
  global unknown_counter
  global empty_counter
  global not_found
  global off_by_one
  global obo_list
  global nf_list
  global files_used_list

  # extracts needed info from table row
  dir_name = row['directory name']
  chrom = row['chrom']
  ref = row['ref']
  alt = row['alt']
  pos = row['start'] + 1
  # NOTE: VCF is 1-based, must covert between
  # 0-based half open BED notation that is contained
  # in the file

  # generates file name and checks of its existence
  file_name = f'{dir_name}{VCF_SUFFIX}'
  file_path = os.path.join(args.directory, file_name)
  if not os.path.exists(file_path):
    error(f'{EXIT} File does not exist: {file_path}')
    sys.exit(1) # safely exits program
  
  # reads the file line-by-line into a list
  with open(file_path, 'r') as vcf_file:
    info(f'Accessing file: {file_name}')
    full_file_list = vcf_file.readlines()
    
    # file statistics incremented
    file_accesses += 1
    if file_name not in files_used_list:
      files_used_list.append(file_name)
  
  # trims list of unneeded info, mainly FORMAT and contig lines
  trimmed_list = [x for x in full_file_list if not x.startswith('##')]

  # processes heading
  heading = trimmed_list[0] # extracts heading str
  trimmed_list.remove(heading) # removes from list
  heading = heading.replace('#', '') # cleans
  heading = heading.split(SEP) # splits heading str into list by SEP
  
  for element in trimmed_list:

    # finds VCF row needed for extraction
    element_list = element.split(SEP) # converts VCF row into list
    
    # extracts comparison data
    vcf_chrom = element_list[heading.index('CHROM')]
    vcf_pos = int(element_list[heading.index('POS')]) # originally str
    vcf_ref = element_list[heading.index('REF')]
    vcf_alt = element_list[heading.index('ALT')]

    # bool comparisons
    chrom_equal = (chrom == vcf_chrom)
    ref_equal = (ref == vcf_ref)
    alt_equal = (alt == vcf_alt)
    # hotfix for off-by-one errors
    # NOTE: works during testing, though something to keep an eye on in the future
    pos_equal_original = (pos == vcf_pos)
    pos_equal_obo_hotfix = ((pos - 1) == vcf_pos)
    pos_equal = pos_equal_original or pos_equal_obo_hotfix

    # creates a tiny comparison table for debugging
    comparison_debug_str = f'Comparison Debug:\nTABLE\t\tVCF\n{chrom}\t\t{vcf_chrom}'
    comparison_debug_str += f'\n{pos}\t\t{vcf_pos}\n{ref}\t\t{vcf_ref}\n{alt}\t\t{vcf_alt}'
    debug(comparison_debug_str)

    # if correct location is found
    if chrom_equal and pos_equal and ref_equal and alt_equal:
      
      # extract set (dragen/pindel/etc.)
      vcf_info = element_list[heading.index('INFO')] # seeks out info section
      start_index = vcf_info.find(SET_BEGIN) + len(SET_BEGIN) # finds index right after SET_BEGIN
      end_index = vcf_info.find(SET_END, start_index) # finds the SET_END that's right after SET_BEGIN 
      coverage_set = vcf_info[start_index : end_index] # extracts data

      # catches if INFO section does not contain "set="
      if (start_index < 0) or (end_index < 0):
        error(f'{EXIT} File does not contain set data.')
        sys.exit(1)

      # increments set counters
      total_annotations += 1
      if coverage_set == 'dragen':
        dragen_counter += 1
        debug('Incrementing DRAGEN.')
      elif coverage_set == 'pindel':
        pindel_counter += 1
        debug('Incrementing PINDEL.')
      elif coverage_set == 'dragen-pindel':
        dragen_pindel_counter += 1
        debug('Incrementing DRAGEN-PINDEL.')
      elif len(coverage_set) == 0:
        empty_counter += 1
        debug('Incrementing empty.')
      else: # if string isn't empty but isn't recognized
        unknown_counter += 1
        debug('Incrementing unknown.')
      
      # counts off-by-one errors
      if not pos_equal_original and pos_equal_obo_hotfix:
        debug('Off-by-one detected.')
        off_by_one += 1
        obo_list.append(file_name)

      # appends coverage_set onto table row 
      row['set'] = coverage_set
      return row ### ENDS FUNCTION
    
  # returns unaltered row if not found
  error(f'Coverage set not found: {file_name}')
  not_found += 1
  nf_list.append(file_name)
  return row



debug('%s begin', SCRIPT_PATH)


# calculates total number of files in inputted directory
total_file_count, vcf_suffix_count = count_files(args.directory)

# read in table
info(f'Reading table: {args.coverage_table}')
df = pd.read_csv(args.coverage_table, sep=SEP)

# applies extraction function
# NOTE: axis=1 == columns, i.e. apply function to each row
df = df.apply(add_set, axis=1)

# re-sorts to ensure that it's sorted in order to take any file
df = df.sort_values(by='json vs bed coverage', ascending=False)

# outputs table to standard output, can be piped into tsv
df.to_csv(sys.stdout, sep=SEP, index=None)

info('----------DIRECTORY STATISTICS----------')
info(f'Total files in directory: {total_file_count}')
info(f'Files with a usable extension: {vcf_suffix_count}')
debug(f'---NOTE: The usable extension: {VCF_SUFFIX} ---')
info(f'VCF files used: {len(files_used_list)}')
info(f'VCF file accesses: {file_accesses}')
debug('---NOTE: VCF file accesses counts each time a file was accessed---')

info('----------SET STATISTICS----------')
info(f'Total set annotations: {total_annotations}')
info(f'DRAGEN sets: {dragen_counter}')
info(f'PINDEL sets: {pindel_counter}')
info(f'DRAGEN-PINDEL sets: {dragen_pindel_counter}')
info(f'Unknown sets: {unknown_counter}')
info(f'Empty sets: {empty_counter}')
info(f'Files where set was not found: {not_found}')
info(f'Files where off-by-one flag was triggered: {off_by_one}')


duplicate_notice = '\t--NOTE: Duplicates may occur if file was caught more than once'

nf_list.append('test')
not_found = 1
obo_list.append('test')

if not_found != 0:

  nf_list.sort()

  # creates debug string
  nf_debug_str = '\n-----VCF files where set was not found-----\n'
  for file in nf_list:
    nf_debug_str += f'\t{file}\n'
  nf_debug_str += duplicate_notice

  debug(nf_debug_str)


if off_by_one != 0:

  obo_list.sort()

  # cerates debug string
  obo_debug_str = '\n-----VCF files where off-by-one flag was triggered-----\n'
  for file in obo_list:
    obo_debug_str += f'\t{file}\n'
  obo_debug_str += duplicate_notice

  debug(obo_debug_str)


debug('%s end', SCRIPT_PATH)